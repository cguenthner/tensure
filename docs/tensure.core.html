<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>tensure.core documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Tensure</span> <span class="project-version">0.1.0</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1 current"><a href="tensure.core.html"><div class="inner"><span>tensure.core</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="tensure.core.html#var-*max-array-print-size*"><div class="inner"><span>*max-array-print-size*</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var--.3Eint"><div class="inner"><span>-&gt;int</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var--.3Enumber"><div class="inner"><span>-&gt;number</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-abs"><div class="inner"><span>abs</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-abs.21"><div class="inner"><span>abs!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-acos"><div class="inner"><span>acos</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-acos.21"><div class="inner"><span>acos!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-add"><div class="inner"><span>add</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-add.21"><div class="inner"><span>add!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-add-dimension"><div class="inner"><span>add-dimension</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-argmax-along"><div class="inner"><span>argmax-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-argmin-along"><div class="inner"><span>argmin-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-array"><div class="inner"><span>array</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-array-.3Evector"><div class="inner"><span>array-&gt;vector</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-array.3F"><div class="inner"><span>array?</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-asin"><div class="inner"><span>asin</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-asin.21"><div class="inner"><span>asin!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-assign.21"><div class="inner"><span>assign!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-atan"><div class="inner"><span>atan</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-atan.21"><div class="inner"><span>atan!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-broadcast"><div class="inner"><span>broadcast</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-broadcast-like"><div class="inner"><span>broadcast-like</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-clone"><div class="inner"><span>clone</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-column-count"><div class="inner"><span>column-count</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-columns"><div class="inner"><span>columns</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-cos"><div class="inner"><span>cos</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-cos.21"><div class="inner"><span>cos!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-cosh"><div class="inner"><span>cosh</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-cosh.21"><div class="inner"><span>cosh!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-dimension-count"><div class="inner"><span>dimension-count</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-dimensionality"><div class="inner"><span>dimensionality</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-div"><div class="inner"><span>div</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-div.21"><div class="inner"><span>div!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ecount"><div class="inner"><span>ecount</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-emap"><div class="inner"><span>emap</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-emap-indexed"><div class="inner"><span>emap-indexed</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-emax"><div class="inner"><span>emax</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-emean"><div class="inner"><span>emean</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-emin"><div class="inner"><span>emin</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-eq"><div class="inner"><span>eq</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-eq.21"><div class="inner"><span>eq!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-equals"><div class="inner"><span>equals</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-eseq"><div class="inner"><span>eseq</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-estdev"><div class="inner"><span>estdev</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-esum"><div class="inner"><span>esum</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-fill.21"><div class="inner"><span>fill!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-filled"><div class="inner"><span>filled</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ge"><div class="inner"><span>ge</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ge.21"><div class="inner"><span>ge!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-gt"><div class="inner"><span>gt</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-gt.21"><div class="inner"><span>gt!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-join-along"><div class="inner"><span>join-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-le"><div class="inner"><span>le</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-le.21"><div class="inner"><span>le!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-log"><div class="inner"><span>log</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-log.21"><div class="inner"><span>log!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-log10"><div class="inner"><span>log10</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-log10.21"><div class="inner"><span>log10!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-lt"><div class="inner"><span>lt</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-lt.21"><div class="inner"><span>lt!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-matrix"><div class="inner"><span>matrix</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-matrix.3F"><div class="inner"><span>matrix?</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-max"><div class="inner"><span>max</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-max-along"><div class="inner"><span>max-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-min"><div class="inner"><span>min</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-min-along"><div class="inner"><span>min-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-mmul"><div class="inner"><span>mmul</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-mset"><div class="inner"><span>mset</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-mset.21"><div class="inner"><span>mset!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-mul"><div class="inner"><span>mul</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-mul.21"><div class="inner"><span>mul!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ne"><div class="inner"><span>ne</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ne.21"><div class="inner"><span>ne!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-negate"><div class="inner"><span>negate</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-ones"><div class="inner"><span>ones</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-outer-product"><div class="inner"><span>outer-product</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-partition-along"><div class="inner"><span>partition-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-permute"><div class="inner"><span>permute</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-permute.21"><div class="inner"><span>permute!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-pm"><div class="inner"><span>pm</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-pow"><div class="inner"><span>pow</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-pow.21"><div class="inner"><span>pow!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-rank"><div class="inner"><span>rank</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-reshape"><div class="inner"><span>reshape</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-row-count"><div class="inner"><span>row-count</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-rows"><div class="inner"><span>rows</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-same-data.3F"><div class="inner"><span>same-data?</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sample-normal"><div class="inner"><span>sample-normal</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sample-rand-int"><div class="inner"><span>sample-rand-int</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sample-uniform"><div class="inner"><span>sample-uniform</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-scalar"><div class="inner"><span>scalar</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-scalar-.3Enumber"><div class="inner"><span>scalar-&gt;number</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-scalar-array"><div class="inner"><span>scalar-array</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-scalar.3F"><div class="inner"><span>scalar?</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-select-axis-range"><div class="inner"><span>select-axis-range</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-select-range"><div class="inner"><span>select-range</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-set-axis-range.21"><div class="inner"><span>set-axis-range!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-set-range.21"><div class="inner"><span>set-range!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-set-rng-seed.21"><div class="inner"><span>set-rng-seed!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-shape"><div class="inner"><span>shape</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-shift"><div class="inner"><span>shift</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sin"><div class="inner"><span>sin</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sin.21"><div class="inner"><span>sin!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sinh"><div class="inner"><span>sinh</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sinh.21"><div class="inner"><span>sinh!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-slices"><div class="inner"><span>slices</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-split"><div class="inner"><span>split</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sqrt"><div class="inner"><span>sqrt</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sqrt.21"><div class="inner"><span>sqrt!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-stack"><div class="inner"><span>stack</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-stringify-neurond"><div class="inner"><span>stringify-neurond</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sub"><div class="inner"><span>sub</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sub.21"><div class="inner"><span>sub!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-submatrix"><div class="inner"><span>submatrix</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-sum-along"><div class="inner"><span>sum-along</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-tan"><div class="inner"><span>tan</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-tan.21"><div class="inner"><span>tan!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-tanh"><div class="inner"><span>tanh</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-tanh.21"><div class="inner"><span>tanh!</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-transpose"><div class="inner"><span>transpose</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-vec.3F"><div class="inner"><span>vec?</span></div></a></li><li class="depth-1"><a href="tensure.core.html#var-zeros"><div class="inner"><span>zeros</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">tensure.core</h1><div class="doc"><pre class="plaintext">A high-level tensor math library for Clojure.
</pre></div><div class="public anchor" id="var-*max-array-print-size*"><h3>*max-array-print-size*</h3><h4 class="dynamic">dynamic</h4><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var--.3Eint"><h3>-&gt;int</h3><div class="usage"><code>(-&gt;int n)</code></div><div class="doc"><pre class="plaintext">Like `-&gt;number` but coerces the return value to an integer.
</pre></div></div><div class="public anchor" id="var--.3Enumber"><h3>-&gt;number</h3><div class="usage"><code>(-&gt;number n)</code></div><div class="doc"><pre class="plaintext">Returns a number that's numerically equivalent to `n`, which may be a Tensure tensor or a clojure/Java
number of any type.</pre></div></div><div class="public anchor" id="var-abs"><h3>abs</h3><div class="usage"><code>(abs nd)</code></div><div class="doc"><pre class="plaintext">Computes the absolute value of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-abs.21"><h3>abs!</h3><div class="usage"><code>(abs! nd)</code></div><div class="doc"><pre class="plaintext">Computes the absolute values of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-acos"><h3>acos</h3><div class="usage"><code>(acos nd)</code></div><div class="doc"><pre class="plaintext">Computes the arcosine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-acos.21"><h3>acos!</h3><div class="usage"><code>(acos! nd)</code></div><div class="doc"><pre class="plaintext">Computes the arccosine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-add"><h3>add</h3><div class="usage"><code>(add)</code><code>(add a)</code><code>(add a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise addition of tensor or scalar arguments, with implicit broadcasting, and returns
a new tensor with the result.</pre></div></div><div class="public anchor" id="var-add.21"><h3>add!</h3><div class="usage"><code>(add! a)</code><code>(add! a &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise addition of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-add-dimension"><h3>add-dimension</h3><div class="usage"><code>(add-dimension nd)</code><code>(add-dimension nd axis)</code></div><div class="doc"><pre class="plaintext">Reshapes `nd` to have an extra dimension of size 1 for axis index `axis`.
</pre></div></div><div class="public anchor" id="var-argmax-along"><h3>argmax-along</h3><div class="usage"><code>(argmax-along nd axis)</code></div><div class="doc"><pre class="plaintext">Given a tensor and either a single axis index or a seq of axis indices, returns a new tensor containing
the index of the maximum element along the axis(es). When more than one axis is specified, the returned
value is a linear index into a tensor where the indicated axes have been collapsed in row major order.</pre></div></div><div class="public anchor" id="var-argmin-along"><h3>argmin-along</h3><div class="usage"><code>(argmin-along nd axis)</code></div><div class="doc"><pre class="plaintext">Given a tensor and either a single axis index or a seq of axis indices, returns a new tensor containing
the index of the minimum element along the axis(es). When more than one axis is specified, the returned
value is a linear index into a tensor where the indicated axes have been collapsed in row major order.</pre></div></div><div class="public anchor" id="var-array"><h3>array</h3><div class="usage"><code>(array data)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor containing `data`, a number, a tensor, or a Clojure data structure consisting of a
seq of seqs or numbers. If a tensor is provided, a clone will be returned.</pre></div></div><div class="public anchor" id="var-array-.3Evector"><h3>array-&gt;vector</h3><div class="usage"><code>(array-&gt;vector nd)</code></div><div class="doc"><pre class="plaintext">Returns a clojure PersistentVector representation of `nd`, or a number if `nd` is a scalar.
</pre></div></div><div class="public anchor" id="var-array.3F"><h3>array?</h3><div class="usage"><code>(array? o)</code></div><div class="doc"><pre class="plaintext">Returns `true` iff `o` is an tensure array.
</pre></div></div><div class="public anchor" id="var-asin"><h3>asin</h3><div class="usage"><code>(asin nd)</code></div><div class="doc"><pre class="plaintext">Computes the arcsine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-asin.21"><h3>asin!</h3><div class="usage"><code>(asin! nd)</code></div><div class="doc"><pre class="plaintext">Computes the arcsine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-assign.21"><h3>assign!</h3><div class="usage"><code>(assign! target src)</code></div><div class="doc"><pre class="plaintext">Mutates the data underlying tensor `target` by setting every element in `target` to the value of the
corresponding element in tensor `src`.</pre></div></div><div class="public anchor" id="var-atan"><h3>atan</h3><div class="usage"><code>(atan nd)</code></div><div class="doc"><pre class="plaintext">Computes the arcsine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-atan.21"><h3>atan!</h3><div class="usage"><code>(atan! nd)</code></div><div class="doc"><pre class="plaintext">Computes the arcsine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-broadcast"><h3>broadcast</h3><div class="usage"><code>(broadcast nd shape)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor produced by braodcasting `nd` to shape `shape`.
</pre></div></div><div class="public anchor" id="var-broadcast-like"><h3>broadcast-like</h3><div class="usage"><code>(broadcast-like src target)</code></div><div class="doc"><pre class="plaintext">Broadcasts `src` into a new tensor that's the shape of `target`. Returns `nil` if `target` is smaaller
than `src` and throws an exception if `src` is smaller than `target` but cannot be broadcast to the shape
of `target`.</pre></div></div><div class="public anchor" id="var-clone"><h3>clone</h3><div class="usage"><code>(clone nd)</code></div><div class="doc"><pre class="plaintext">Copies the data underlying `nd` and returns a new nd array referencing the copied data.
</pre></div></div><div class="public anchor" id="var-column-count"><h3>column-count</h3><div class="usage"><code>(column-count nd)</code></div><div class="doc"><pre class="plaintext">Returns the size of the second axis of `nd`. This is equal to the number of columns in `nd` if `nd` is a
matrix. Equivalent to `(dimension-count nd 1)`.</pre></div></div><div class="public anchor" id="var-columns"><h3>columns</h3><div class="usage"><code>(columns nd)</code></div><div class="doc"><pre class="plaintext">If `nd` is a tensor, returns a seq of views of vectors along `nd`'s second-to-innermost dimension. If `nd`
is a matrix, this corresponds to a seq of column vectors. Returns a seq of scalars if `nd` is a vector.
Throws an exception if `nd` is a scalar.</pre></div></div><div class="public anchor" id="var-cos"><h3>cos</h3><div class="usage"><code>(cos nd)</code></div><div class="doc"><pre class="plaintext">Computes the cosine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-cos.21"><h3>cos!</h3><div class="usage"><code>(cos! nd)</code></div><div class="doc"><pre class="plaintext">Computes the cosine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-cosh"><h3>cosh</h3><div class="usage"><code>(cosh nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic cosine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-cosh.21"><h3>cosh!</h3><div class="usage"><code>(cosh! nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic cosine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-dimension-count"><h3>dimension-count</h3><div class="usage"><code>(dimension-count nd dim-index)</code></div><div class="doc"><pre class="plaintext">Returns the size of the dimension corresponding to `dim-index`.
</pre></div></div><div class="public anchor" id="var-dimensionality"><h3>dimensionality</h3><div class="usage"></div><div class="doc"><pre class="plaintext">Alias for `rank` provided for compatability with `core.matrix`.
</pre></div></div><div class="public anchor" id="var-div"><h3>div</h3><div class="usage"><code>(div a)</code><code>(div a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise division of tensor or scalar arguments, with implicit broadcasting, and returns
a new tensor with the result.</pre></div></div><div class="public anchor" id="var-div.21"><h3>div!</h3><div class="usage"><code>(div! a)</code><code>(div! a &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise division of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-ecount"><h3>ecount</h3><div class="usage"><code>(ecount nd)</code></div><div class="doc"><pre class="plaintext">Returns the total number of elements in `nd`.
</pre></div></div><div class="public anchor" id="var-emap"><h3>emap</h3><div class="usage"><code>(emap f nd &amp; more)</code></div><div class="doc"><pre class="plaintext">Element-wise map over all elemends in one or more tensors, which must all be the same shape. Returns a new
tensor of that shape that contains the result of applying `f` to the elements in the equivalent positions
in all tensor arguments.</pre></div></div><div class="public anchor" id="var-emap-indexed"><h3>emap-indexed</h3><div class="usage"><code>(emap-indexed f nd &amp; more)</code></div><div class="doc"><pre class="plaintext">Element-wise map over all elemends in one or more tensors. Returns a new tensor that's the same shape as
`nd` and that contains the result of applying `f` to an index vector and all the elements in that position
in all tensor arguemnts.</pre></div></div><div class="public anchor" id="var-emax"><h3>emax</h3><div class="usage"><code>(emax nd)</code></div><div class="doc"><pre class="plaintext">Returns a new scalar that is the maximum element in `nd`.
</pre></div></div><div class="public anchor" id="var-emean"><h3>emean</h3><div class="usage"><code>(emean nd)</code></div><div class="doc"><pre class="plaintext">Returns a new scalar that is the mean of all elements in `nd`.
</pre></div></div><div class="public anchor" id="var-emin"><h3>emin</h3><div class="usage"><code>(emin nd)</code></div><div class="doc"><pre class="plaintext">Returns a new scalar that is the minimum element in `nd`.
</pre></div></div><div class="public anchor" id="var-eq"><h3>eq</h3><div class="usage"><code>(eq a)</code><code>(eq a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise equality of tensor or scalar arguments, with implicit broadcasting, and places the
result in the first argument.</pre></div></div><div class="public anchor" id="var-eq.21"><h3>eq!</h3><div class="usage"><code>(eq! a)</code><code>(eq! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise equality of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-equals"><h3>equals</h3><div class="usage"><code>(equals)</code><code>(equals a b)</code><code>(equals a b eps)</code></div><div class="doc"><pre class="plaintext">Returns true iff every element of `a` is within +/- `eps` of the corresponding element in `b`, and
false otherwise. `eps` defaults to 1e-6.</pre></div></div><div class="public anchor" id="var-eseq"><h3>eseq</h3><div class="usage"><code>(eseq nd)</code></div><div class="doc"><pre class="plaintext">Returns a seq of `java.lang.Float`s representing the elements in `nd` in row-major order.
</pre></div></div><div class="public anchor" id="var-estdev"><h3>estdev</h3><div class="usage"><code>(estdev nd)</code></div><div class="doc"><pre class="plaintext">Returns a new scalar that is the standard deviation of all elements in `nd`.
</pre></div></div><div class="public anchor" id="var-esum"><h3>esum</h3><div class="usage"><code>(esum nd)</code></div><div class="doc"><pre class="plaintext">Returns a new scalar that is the sum of all elements in `nd`.
</pre></div></div><div class="public anchor" id="var-fill.21"><h3>fill!</h3><div class="usage"><code>(fill! nd n)</code></div><div class="doc"><pre class="plaintext">Mutates the data underlying `nd` by setting every element to number `n`. Returns `nd`.
</pre></div></div><div class="public anchor" id="var-filled"><h3>filled</h3><div class="usage"><code>(filled shape n)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor of `shape` in which every element is number `n`.
</pre></div></div><div class="public anchor" id="var-ge"><h3>ge</h3><div class="usage"><code>(ge a)</code><code>(ge a b)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor containing the elementwise result of (&gt;= a b), with implicit broadcasting.
</pre></div></div><div class="public anchor" id="var-ge.21"><h3>ge!</h3><div class="usage"><code>(ge! a)</code><code>(ge! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise &gt;= of tensor or scalar arguments, with implicit broadcasting, and places the result
in the first argument.</pre></div></div><div class="public anchor" id="var-gt"><h3>gt</h3><div class="usage"><code>(gt a)</code><code>(gt a b)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor containing the elementwise result of (&gt; a b), with implicit broadcasting.
</pre></div></div><div class="public anchor" id="var-gt.21"><h3>gt!</h3><div class="usage"><code>(gt! a)</code><code>(gt! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise &gt; of tensor or scalar arguments, with implicit broadcasting, and places the result
in the first argument.</pre></div></div><div class="public anchor" id="var-join-along"><h3>join-along</h3><div class="usage"><code>(join-along dim &amp; nds)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor produced by concatenating tensors `nds` along dimension `dim`. `nds` must be the
same shape except for `dim`.</pre></div></div><div class="public anchor" id="var-le"><h3>le</h3><div class="usage"><code>(le a)</code><code>(le a b)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor containing the elementwise result of (&lt;= a b), with implicit broadcasting.
</pre></div></div><div class="public anchor" id="var-le.21"><h3>le!</h3><div class="usage"><code>(le! a)</code><code>(le! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise &lt;= of tensor or scalar arguments, with implicit broadcasting, and places the result
in the first argument.</pre></div></div><div class="public anchor" id="var-log"><h3>log</h3><div class="usage"><code>(log nd)</code></div><div class="doc"><pre class="plaintext">Computes the natural logarithm of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-log.21"><h3>log!</h3><div class="usage"><code>(log! nd)</code></div><div class="doc"><pre class="plaintext">Computes the natural logarithm of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-log10"><h3>log10</h3><div class="usage"><code>(log10 nd)</code></div><div class="doc"><pre class="plaintext">Computes the base 10 logarithm of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-log10.21"><h3>log10!</h3><div class="usage"><code>(log10! nd)</code></div><div class="doc"><pre class="plaintext">Computes the base 10 logarithm of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-lt"><h3>lt</h3><div class="usage"><code>(lt a)</code><code>(lt a b)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor containing the elementwise result of (&lt; a b), with implicit broadcasting.
</pre></div></div><div class="public anchor" id="var-lt.21"><h3>lt!</h3><div class="usage"><code>(lt! a)</code><code>(lt! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise &lt; of tensor or scalar arguments, with implicit broadcasting, and places the result
in the first argument.</pre></div></div><div class="public anchor" id="var-matrix"><h3>matrix</h3><div class="usage"><code>(matrix data)</code></div><div class="doc"><pre class="plaintext">Given a two-dimensional collection of `data`, returns a new rank-2 tensor (matrix) containing those data.
Equivalent to `array` but throws an `Exception` if `data` is not two-dimensional.</pre></div></div><div class="public anchor" id="var-matrix.3F"><h3>matrix?</h3><div class="usage"><code>(matrix? nd)</code></div><div class="doc"><pre class="plaintext">Returns `true` iff `nd` is a rank-2 tensure tensor (i.e. a matrix).
</pre></div></div><div class="public anchor" id="var-max"><h3>max</h3><div class="usage"><code>(max a)</code><code>(max a b)</code><code>(max a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Returns the elementwise max of tensors, broadcasting when necessary.
</pre></div></div><div class="public anchor" id="var-max-along"><h3>max-along</h3><div class="usage"></div><div class="doc"><pre class="plaintext">Returns a new tensor that's the result of finding the minimum of `nd` along `axes`, either a single axis
or a vector of axes. If `collapse` is `true` (the default), the reduced dimensions are removed from the
result; otherwise, the rank of the returned tensor will be the same as the rank of the input tensor, with
the reduced axes having size 1.</pre></div></div><div class="public anchor" id="var-min"><h3>min</h3><div class="usage"><code>(min a)</code><code>(min a b)</code><code>(min a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Returns the elementwise min of tensors, broadcasting when necessary.
</pre></div></div><div class="public anchor" id="var-min-along"><h3>min-along</h3><div class="usage"></div><div class="doc"><pre class="plaintext">Returns a new tensor that's the result of finding the minimum of `nd` along `axes`, either a single axis
or a vector of axes. If `collapse` is `true` (the default), the reduced dimensions are removed from the
result; otherwise, the rank of the returned tensor will be the same as the rank of the input tensor, with
the reduced axes having size 1.</pre></div></div><div class="public anchor" id="var-mmul"><h3>mmul</h3><div class="usage"><code>(mmul)</code><code>(mmul a)</code><code>(mmul a b)</code><code>(mmul a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Computes:
  - the inner product of `a` and `b` when `a` and `b` are matrices or vectors
  - the inner product of the highest dimension of the tensor with the vector when one argument is a tensor
    and the other is a vector
  - the tensor dot product of `a` and `b` when either `a` or `b` is a tensor and the other is a tensor
    or matrix
  - element-wise product when `a` or `b` is a scalar
When a and b are tensors of shape [a b c d e] and [f g h i j], then the product will be a tensor of shape
[a b c d g e h i j] - i.e. the result is produced by multiplying every d x e matrix from `a` by every
f x g matrix from `b` to get a * b * c * h * i * j d x g products.</pre></div></div><div class="public anchor" id="var-mset"><h3>mset</h3><div class="usage"><code>(mset nd &amp; more)</code></div><div class="doc"><pre class="plaintext">Returns a clone of `nd` with the value of a particular element set to a certain value. `more` is a seq
like [...indices, value]. For example, `(mset! scalar 7)` sets a mutable scalar to 7, `(mset! vector 1 7)`
sets the element at index 1 in a vector to 7, `(mset! matrix 1 3 7)` sets the element in the first row,
third column of a matrix to 7, and so on. Mutates `nd`.</pre></div></div><div class="public anchor" id="var-mset.21"><h3>mset!</h3><div class="usage"><code>(mset! nd &amp; more)</code></div><div class="doc"><pre class="plaintext">Sets the value of a particular element in `nd`. `more` is a seq like [...indices, value]. For example,
`(mset! scalar 7)` sets a mutable scalar to 7, `(mset! vector 1 7)` sets the element at index 1 in a
vector to 7, `(mset! matrix 1 3 7)` sets the element in the first row, third column of a matrix to 7,
and so on. Mutates `nd`.</pre></div></div><div class="public anchor" id="var-mul"><h3>mul</h3><div class="usage"><code>(mul)</code><code>(mul a)</code><code>(mul a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise multiplication of tensor or scalar arguments, with implicit broadcasting, and returns
a new tensor with the result.</pre></div></div><div class="public anchor" id="var-mul.21"><h3>mul!</h3><div class="usage"><code>(mul! a)</code><code>(mul! a &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise multiplication of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-ne"><h3>ne</h3><div class="usage"><code>(ne a)</code><code>(ne a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise inequality of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-ne.21"><h3>ne!</h3><div class="usage"><code>(ne! a)</code><code>(ne! a b)</code></div><div class="doc"><pre class="plaintext">Calculates elementwise inequality of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-negate"><h3>negate</h3><div class="usage"><code>(negate nd)</code></div><div class="doc"><pre class="plaintext">Returns the element-wise negation of `nd`.
</pre></div></div><div class="public anchor" id="var-ones"><h3>ones</h3><div class="usage"><code>(ones shape)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor of `shape` filled with 1's.
</pre></div></div><div class="public anchor" id="var-outer-product"><h3>outer-product</h3><div class="usage"><code>(outer-product)</code><code>(outer-product a)</code><code>(outer-product a b)</code><code>(outer-product a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Returns the outer product of the tensor arguments.
</pre></div></div><div class="public anchor" id="var-partition-along"><h3>partition-along</h3><div class="usage"><code>(partition-along nd)</code><code>(partition-along nd axis)</code><code>(partition-along nd axis partition-size)</code><code>(partition-along nd axis partition-size step-size)</code></div><div class="doc"><pre class="plaintext">Splits `nd` along `axis` into chunks of `partition-size` spaced by `step-size`. The last chunk is
included even if it is not `partition-size`; this is similar to `clojure.core/partition-all` but for
tensors rather than arbitrary collections. If not provided, `axis` defaults to `0`, `partition-size`
defaults to `1`, and `step-size` defaults to `partition-size`. Returns a seq of tensors.</pre></div></div><div class="public anchor" id="var-permute"><h3>permute</h3><div class="usage"><code>(permute nd axes)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor (possibly a view) in which the dimensions of `nd` have been reordered as specified in
`axes`, a seq of axis indices. `axes` must contain every natural number in [0, rank of nd). The result and
`nd` share data but will have different shapes.</pre></div></div><div class="public anchor" id="var-permute.21"><h3>permute!</h3><div class="usage"><code>(permute! nd axes)</code></div><div class="doc"><pre class="plaintext">Like `permuted-view` but mutates `nd` rather than returning a new view.
</pre></div></div><div class="public anchor" id="var-pm"><h3>pm</h3><div class="usage"></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-pow"><h3>pow</h3><div class="usage"><code>(pow a)</code><code>(pow a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Computes the elementwise power function a^more[0]^more[1]... and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-pow.21"><h3>pow!</h3><div class="usage"><code>(pow! a)</code><code>(pow! a &amp; more)</code></div><div class="doc"><pre class="plaintext">Computes the elementwise power function a^more[0]^more[1]... modifying `a` in place with the results.
</pre></div></div><div class="public anchor" id="var-rank"><h3>rank</h3><div class="usage"><code>(rank nd)</code></div><div class="doc"><pre class="plaintext">Returns the `rank` of `nd`. Equivalent to `dimensionality`.
</pre></div></div><div class="public anchor" id="var-reshape"><h3>reshape</h3><div class="usage"><code>(reshape nd shape)</code></div><div class="doc"><pre class="plaintext">Returns a tensor, possibly representing a view over the same data as `nd`, with shape `shape`.
`(apply * shape)` must equal `(ecount nd)` (i.e. the number of elements in the original tensor and the
output tensor must be the same). The order of elements in the input vector is retained in row major order
in the output tensor.</pre></div></div><div class="public anchor" id="var-row-count"><h3>row-count</h3><div class="usage"><code>(row-count nd)</code></div><div class="doc"><pre class="plaintext">Returns the size of the first axis of `nd`. This is equal to the number of rows in `nd` if `nd` is a
matrix. Equivalent to `(dimension-count nd 0)`.</pre></div></div><div class="public anchor" id="var-rows"><h3>rows</h3><div class="usage"><code>(rows nd)</code></div><div class="doc"><pre class="plaintext">If `nd` is a tensor, returns a seq of views of vectors along `nd`'s innermost dimension. If `nd` is a
matrix, this corresponds to a seq of row vectors. Throws an exception if `nd` is a scalar.</pre></div></div><div class="public anchor" id="var-same-data.3F"><h3>same-data?</h3><div class="usage"><code>(same-data? &amp; nds)</code></div><div class="doc"><pre class="plaintext">Returns true iff all arguments are tensors referencing the same underling data.
</pre></div></div><div class="public anchor" id="var-sample-normal"><h3>sample-normal</h3><div class="usage"><code>(sample-normal shape seed)</code><code>(sample-normal shape)</code></div><div class="doc"><pre class="plaintext">Returns an array of `shape` with elements drawn from a normal distribution with mean 0 and standard
deviation 1 using the given random number generator `seed`. If `shape` is an integer, returns a vector of
that length.</pre></div></div><div class="public anchor" id="var-sample-rand-int"><h3>sample-rand-int</h3><div class="usage"><code>(sample-rand-int shape n)</code><code>(sample-rand-int shape n seed)</code></div><div class="doc"><pre class="plaintext">Returns an array of `shape` with elements drawn from a uniform integer distribution over [0, n) using the
given random number generator `seed`. If `shape` is an integer, returns a vector of that length. The
result's elements will be integer-valued but not necessarily of type Integer.</pre></div></div><div class="public anchor" id="var-sample-uniform"><h3>sample-uniform</h3><div class="usage"><code>(sample-uniform shape seed)</code><code>(sample-uniform shape)</code></div><div class="doc"><pre class="plaintext">Returns an array of `shape` with elements sampled uniformly from [0, 1) using the given random number
generator `seed`. If `shape` is an integer, returns a vector of that length.</pre></div></div><div class="public anchor" id="var-scalar"><h3>scalar</h3><div class="usage"><code>(scalar n)</code></div><div class="doc"><pre class="plaintext">Given number `n`, returns a new scalar.
</pre></div></div><div class="public anchor" id="var-scalar-.3Enumber"><h3>scalar-&gt;number</h3><div class="usage"><code>(scalar-&gt;number nd)</code></div><div class="doc"><pre class="plaintext">Returns a `java.lang.Float` that's numerically equivalent to scalar `nd`.
</pre></div></div><div class="public anchor" id="var-scalar-array"><h3>scalar-array</h3><div class="usage"></div><div class="doc"><pre class="plaintext">Equivalent to `scalar`, included only for `core.matrix` compatability.
</pre></div></div><div class="public anchor" id="var-scalar.3F"><h3>scalar?</h3><div class="usage"><code>(scalar? nd)</code></div><div class="doc"><pre class="plaintext">Returns `true` iff `nd` is a rank-0 tensure tensor (i.e. a scalar).
</pre></div></div><div class="public anchor" id="var-select-axis-range"><h3>select-axis-range</h3><div class="usage"><code>(select-axis-range nd axis selection)</code></div><div class="doc"><pre class="plaintext">Like `select-range` but applies a selection to only a single axis (selects everything along other axes).
`selection` must be a valid `selection` argument to `select-range`, and `axis` must be a valid axis index.</pre></div></div><div class="public anchor" id="var-select-range"><h3>select-range</h3><div class="usage"><code>(select-range nd &amp; selections)</code></div><div class="doc"><pre class="plaintext">Returns a view of a (not necessarily continuous) selection of `nd`. `selections` is a seq of objects
indicating what range of the corresponding dimension should be selected. These objects can be:
  - a number - indicating a slice of that dimension (the dimension will be eliminated)
  - a two-element vector like [start stop] - indicating a range of slices in [start, stop)
  - a three-element vector like [start stop step] - indicating a range of every `step`th slice in
    [start, stop)
  - `:first` - indicating the first slice (the dimension will be eliminated)
  - `:last` - indicating the last slice (the dimension will be eliminated)
  - `:all` - indicating that all slices through that dimension should be kept
  - `:butlast` - indicating that all but the last slice of that dimension should be kept
  - `:rest` - indicating that all but the first slice of that dimension should be kept
The size of `selections` should match the dimensionality of `nd`.</pre></div></div><div class="public anchor" id="var-set-axis-range.21"><h3>set-axis-range!</h3><div class="usage"><code>(set-axis-range! nd axis selection val)</code></div><div class="doc"><pre class="plaintext">Like `set-range!` but sets a selection along only a single axis (sets everything along other axes).
`selection` must be a valid `selection` argument to `select-range`, and `axis` must be a valid axis index.</pre></div></div><div class="public anchor" id="var-set-range.21"><h3>set-range!</h3><div class="usage"><code>(set-range! nd &amp; args)</code></div><div class="doc"><pre class="plaintext">Like `select-range`, but mutates the data underlying the specified selection of `nd` by setting every
element to the corresponding value in the last argument, a source tensor. I.e., arguments should be:
  (set-range! target-tensor selection-for-axis-0 selection-for-axis-1 ... source-tensor)
`source-tensor` must have the same shape as the selection from `target-tensor`.</pre></div></div><div class="public anchor" id="var-set-rng-seed.21"><h3>set-rng-seed!</h3><div class="usage"><code>(set-rng-seed! seed)</code></div><div class="doc"><pre class="plaintext">Sets the random number generator (RNG) seed used by all statistical sampling tensor creators (e.g.
`sample-uniform`, etc.</pre></div></div><div class="public anchor" id="var-shape"><h3>shape</h3><div class="usage"><code>(shape nd)</code></div><div class="doc"><pre class="plaintext">Returns a Clojure vector representing the `shape` of `nd`.
</pre></div></div><div class="public anchor" id="var-shift"><h3>shift</h3><div class="usage"><code>(shift nd dim shift-amount)</code><code>(shift nd shifts)</code></div><div class="doc"><pre class="plaintext">Shifts the elements in `nd` by `shift-amount` elements along single dimension `dim` or by the number of
elements specified in `shifts`, a vector of shift amounts for the axes at that index. Positive shifts are
up/left, and negative shifts are down/right. For instance, `(shift nd 1 3)` shifts the columns of a matrix
left by three elements; and `(shift nd [-1, 2])` shifts the rows of `nd` down by 1 and the columns of nd
left by 2 (the first row and last two columns will be all zeros).</pre></div></div><div class="public anchor" id="var-sin"><h3>sin</h3><div class="usage"><code>(sin nd)</code></div><div class="doc"><pre class="plaintext">Computes the sine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-sin.21"><h3>sin!</h3><div class="usage"><code>(sin! nd)</code></div><div class="doc"><pre class="plaintext">Computes the sine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-sinh"><h3>sinh</h3><div class="usage"><code>(sinh nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic sine of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-sinh.21"><h3>sinh!</h3><div class="usage"><code>(sinh! nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic sine of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-slices"><h3>slices</h3><div class="usage"><code>(slices nd)</code><code>(slices nd dimension)</code></div><div class="doc"><pre class="plaintext">Returns a seq of slice views through `nd` along the indicated `dimension` (defaults to the first dimension).
</pre></div></div><div class="public anchor" id="var-split"><h3>split</h3><div class="usage"><code>(split nd)</code><code>(split nd axis)</code></div><div class="doc"><pre class="plaintext">Splits `nd` along `axis`, returning a seq of tensors with size 1 along `axis` and all other axes the same
size as `nd`. Equivalent to `(partition-along nd axis 1 1)`.</pre></div></div><div class="public anchor" id="var-sqrt"><h3>sqrt</h3><div class="usage"><code>(sqrt nd)</code></div><div class="doc"><pre class="plaintext">Computes the square root of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-sqrt.21"><h3>sqrt!</h3><div class="usage"><code>(sqrt! nd)</code></div><div class="doc"><pre class="plaintext">Computes the square root of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-stack"><h3>stack</h3><div class="usage"><code>(stack &amp; args)</code></div><div class="doc"><pre class="plaintext">Given a series of tensors and, optionally, an axis index, returns a new tensor produced by 'stacking'
the tensors along that axis. The axis index can be specified as the first argument but otherwise defaults
to 0:
  (stack nd-a nd-b nd-c ...)
  (stack axis nd-a nd-b nd-c ...)
The input tensors must have identical shapes. The returned tensor will be the same shape as the input
tensors but will have an extra dimension at index `axis` of size `(count nds)`.</pre></div></div><div class="public anchor" id="var-stringify-neurond"><h3>stringify-neurond</h3><div class="usage"><code>(stringify-neurond nd)</code></div><div class="doc"><pre class="plaintext"></pre></div></div><div class="public anchor" id="var-sub"><h3>sub</h3><div class="usage"><code>(sub)</code><code>(sub a)</code><code>(sub a b &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise subtraction of tensor or scalar arguments, with implicit broadcasting, and returns
a new tensor with the result.</pre></div></div><div class="public anchor" id="var-sub.21"><h3>sub!</h3><div class="usage"><code>(sub! a)</code><code>(sub! a &amp; more)</code></div><div class="doc"><pre class="plaintext">Performs elementwise subtraction of tensor or scalar arguments, with implicit broadcasting, and places
the result in the first argument.</pre></div></div><div class="public anchor" id="var-submatrix"><h3>submatrix</h3><div class="usage"><code>(submatrix nd dimension index-range)</code><code>(submatrix nd row-start row-length col-start col-length)</code><code>(submatrix nd index-ranges)</code></div><div class="doc"><pre class="plaintext">Returns a view of a subregion of tensor `nd`. The result will have the same dimensionality as `nd`. The
subregion can be specified as:
- `row-start`, `row-length`, `col-start`, `col-length`, where `row-start` and `col-start` are the starting
  indices for the view in the 0th and 1st dimensions of `nd`, respectively, and `row-length` and `col-length`
  are the sizes of the subregion in its 0th and 1st dimension, respectively
- `dimension`, `index-ranges`, where `dimension` is a dimension index and `index-range` is a two element
  vector like [`start-index`, `length`] that describes where the subregion should start and how long it
  should be in that dimension (the subregion will include the full length of all other dimensions)
- `index-ranges`, a seq where each element is either a vector like [`start-index`, `length`] or `nil`
  (indicating the entire length of the dimension should be included. If the length of the seq is less than
  the dimensionality of `nd`, the entirety of trailing dimensions is included.</pre></div></div><div class="public anchor" id="var-sum-along"><h3>sum-along</h3><div class="usage"></div><div class="doc"><pre class="plaintext">Returns a new tensor that's the result of summing `nd` along `axes`, either a single axis or a vector of
axes. If `collapse` is `true` (the default), the summed dimensions are removed from the result; otherwise,
the rank of the returned tensor will be the same as the rank of the input tensor, with the reduced axes
having size 1.</pre></div></div><div class="public anchor" id="var-tan"><h3>tan</h3><div class="usage"><code>(tan nd)</code></div><div class="doc"><pre class="plaintext">Computes the tangent of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-tan.21"><h3>tan!</h3><div class="usage"><code>(tan! nd)</code></div><div class="doc"><pre class="plaintext">Computes the tangent of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-tanh"><h3>tanh</h3><div class="usage"><code>(tanh nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic tangent of all elements in `nd`, and returns a new tensor with the result.
</pre></div></div><div class="public anchor" id="var-tanh.21"><h3>tanh!</h3><div class="usage"><code>(tanh! nd)</code></div><div class="doc"><pre class="plaintext">Computes the hyperbolic tangent of all elements in `nd`, modifying `nd` in place with the results.
</pre></div></div><div class="public anchor" id="var-transpose"><h3>transpose</h3><div class="usage"><code>(transpose nd)</code></div><div class="doc"><pre class="plaintext">Returns the tensor transpose of `nd`.
</pre></div></div><div class="public anchor" id="var-vec.3F"><h3>vec?</h3><div class="usage"><code>(vec? nd)</code></div><div class="doc"><pre class="plaintext">Returns `true` iff `nd` is a rank-1 tensure tensor (i.e. a vector).
</pre></div></div><div class="public anchor" id="var-zeros"><h3>zeros</h3><div class="usage"><code>(zeros shape)</code></div><div class="doc"><pre class="plaintext">Returns a new tensor of `shape` filled with 0's.
</pre></div></div></div></body></html>